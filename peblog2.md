# Vibe Coding with Convex: From Chef Template to Production in Weeks

Learning to ship AI-powered apps through strategic prompting and fearless iteration

## The Download That Changed Everything

I downloaded a template from chef.convex.dev and shipped a live game with thousands of users. No overthinking, no perfectionism. Just curiosity, AI agents, and a willingness to experiment with real-time databases and prompt engineering at scale.

Here's what I learned about vibe coding with Convex that goes way beyond traditional tutorials.

## Start with Data Models, Not Features

Instead of prompting "build a word game," I started with "design a schema for competitive word guessing with real-time collaboration." The AI immediately understood relationships: users, games, attempts, hints, challenges.

When you lead with domain modeling, AI gives you better architecture decisions. It thinks in terms of entities and relationships rather than just implementing features.

This saved me from three major refactors. When I added challenge mode, the schema already supported multiple players. When I added friend collaboration, the invite system was already there.

## Custom Rules Are Your Secret Weapon

Most developers ignore custom Cursor rules. That's leaving performance on the table. I built rules that encoded Convex best practices, my preferred code style, and domain knowledge.

My three most valuable rules:

- Convex function patterns (always validators, prefer mutations over actions)
- Authentication flows (Clerk integration patterns)
- Error handling strategies (graceful failures, user-friendly messages)

These rules transformed Cursor from a generic coding assistant into a domain expert for my specific stack.

## Write PRDs for AI, Not Humans

Traditional product docs are terrible for AI agents. Too verbose, too ambiguous, too focused on business justification rather than technical specification.

My PRD workflow:

1. Brain dump the core concept
2. Define the data model with entity relationships
3. Map user flows step by step
4. Identify edge cases and failure modes
5. Write specific, testable acceptance criteria

I rewrote the challenge mode PRD three times until it was perfect for AI consumption. The result: AI agents implemented entire features without constant clarification questions.

## Think Systems, Not Individual Prompts

Stop thinking about individual prompts. Start thinking about prompt systems. How does the AI that generates your database schema talk to the AI that writes your frontend components?

I built a prompt chain:

1. Domain expert AI designs the data model
2. Backend AI implements Convex functions with validation
3. Frontend AI builds React components matching API contracts
4. Testing AI writes integration tests verifying the flow

Each AI had access to outputs from previous ones. Consistency through handoffs.

## Constraints Make AI Better

"Build a word game" produces garbage. "Build a word game where users get exactly 3 attempts to guess a 5-8 letter word generated by AI, with timer pressure on the final attempt and optional hints after failed attempts" produces excellent code.

More constraints eliminate ambiguity and force AI to make decisions within your domain rather than hallucinating generic solutions.

## Real-Time Changes Everything

Convex's real-time database made prompt engineering feel magical. I could prompt for a feature, watch AI generate code, and immediately see it working live. The feedback loop went from minutes to seconds.

This changed how I prompted. Instead of describing complex state management, I prompted for specific mutations and watched real-time updates happen. AI got immediate feedback on whether its approach worked.

## Compose Components, Don't Build Monoliths

Early mistake: prompting for entire pages at once. Better approach: prompt for small, composable components then compose them through additional prompts.

MyScores, UserProfile, ConfirmDialog. Each prompted separately with clear interfaces, then composed into larger features. AI got better at building cohesive experiences from smaller pieces.

## Test-Driven Prompting Works

Instead of prompting for implementation and hoping it works, I started prompting for tests first, then implementation that passes tests.

"Write integration tests for challenge mode creation, invitation, and gameplay flow."

Then: "Implement challenge mode functionality to pass these tests."

AI produced much more reliable code when it had test cases to satisfy.

## Documentation Scales Knowledge

The files.md document wasn't just project documentation. It was a knowledge base for AI agents. When I prompted for new features, I included relevant sections as context.

This scaled domain knowledge across conversations. New AI agents understood existing architecture without me explaining it every time.

## Performance Needs Domain Knowledge

Generic "make it fast" prompts don't work. Instead: "Optimize for OpenAI API rate limits, implement exponential backoff, cache responses when appropriate, and fail gracefully with user-friendly messages."

AI needs specific performance constraints to generate efficient code.

## UI Needs Aesthetic Constraints

"Build a beautiful UI" produces generic Bootstrap interfaces. "Build a UI using sharp edges, bold shadows, high contrast, and black/white color scheme" produces distinctive, cohesive designs.

UI prompting requires aesthetic constraints just like feature prompting requires functional constraints.

## The Meta Lesson

Building with Convex taught me that vibe coding isn't just about moving fast. It's about building systems where humans and AI collaborate effectively at every level.

The future belongs to developers who can architect through conversation, who can turn ideas into running code through strategic prompting, and who understand that the best AI seamlessly extends your own thinking.

Chef.convex.dev was just the beginning. The real magic happens when you stop thinking about AI as a tool and start thinking about it as a development partner that scales your ability to build at the speed of thought.

Want to see these lessons in practice? The entire codebase demonstrates every principle in action. Real prompts, real results, real users at impossible.fun.

Built with Convex, shipped fast, iterated with real user feedback.
